{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from math import sqrt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, corpus, n_heads, embd_dim=512):\n",
    "        self.embd_dim = embd_dim\n",
    "        self.tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
    "        self.vocab = {}\n",
    "        self.input = []\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.learning_rate = 0.001\n",
    "#         self.lookahead = []\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def indx_map(self,Y):\n",
    "        arr = [0]*len(Y)\n",
    "\n",
    "        print(arr)\n",
    "        for i in range(len(Y)):\n",
    "            arr[i] = Y[i]\n",
    "        return arr\n",
    "    \n",
    "    def one_hot(self, Y, max):\n",
    "        k = self.indx_map(Y)\n",
    "        one_hot_Y = np.zeros((Y.size, max + 1))\n",
    "        one_hot_Y[np.arange(Y.size), k] = 1\n",
    "        return one_hot_Y  \n",
    "\n",
    "    def vocab_creation(self):\n",
    "        self.vocab['sos'] = 0\n",
    "        indx = 1\n",
    "\n",
    "        for sentence in self.tokenized_corpus:\n",
    "            for i,word in enumerate(sentence):\n",
    "                # if i == global_indx :\n",
    "                if word not in self.vocab :\n",
    "                    self.vocab[word] = indx\n",
    "                else:\n",
    "                    continue\n",
    "                indx += 1\n",
    "        self.num_words = len(self.vocab)\n",
    "        \n",
    "    def word_embeddings(self):\n",
    "        data = []\n",
    "        for i in self.tokenized_corpus:\n",
    "            print(i)\n",
    "            temp = ['sos']\n",
    "\n",
    "            for j in i :\n",
    "                temp.append(j.lower())\n",
    "\n",
    "            data.append(temp)\n",
    "\n",
    "        model = Word2Vec(sentences=data, vector_size=512, window=5, min_count=1, workers=4)\n",
    "        words = list(model.wv.index_to_key)\n",
    "        self.words = words\n",
    "        embeddings_matrix = np.zeros((len(words), model.vector_size))\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            embeddings_matrix[i] = model.wv[word]\n",
    "\n",
    "        self.embeddings = embeddings_matrix * sqrt(self.embd_dim)\n",
    "        \n",
    "    def positional_encoding(self, n):\n",
    "        self.num_words = n\n",
    "        self.position_encodings = np.zeros((self.num_words, self.embd_dim))\n",
    "        for pos in range(self.num_words):\n",
    "            for i in range(0, self.embd_dim, 2):\n",
    "                angle = pos / np.power(10000, (2 * i) / np.float32(self.embd_dim))\n",
    "                self.position_encodings[pos, i] = np.sin(angle)\n",
    "                self.position_encodings[pos, i + 1] = np.cos(angle)\n",
    "        \n",
    "    \n",
    "    def layer_normalization(self, x, epsilon=1e-6):\n",
    "        gamma = np.ones(self.embd_dim)\n",
    "        beta = np.zeros(self.embd_dim)\n",
    "\n",
    "        mean = np.mean(x, axis=-1, keepdims=True)\n",
    "        variance = np.var(x, axis=-1, keepdims=True)\n",
    "        x_normalized = (x - mean) / np.sqrt(variance + epsilon)\n",
    "\n",
    "        output = gamma * x_normalized + beta\n",
    "        return output\n",
    "\n",
    "    def feed_forward(self):\n",
    "        self.ffn1 = Layer_Dense(self.embd_dim, self.embd_dim * 4, 10)\n",
    "        self.ffnact = Activation_ReLU()\n",
    "        self.ffn2 = Layer_Dense(self.embd_dim * 4, self.embd_dim, 9)\n",
    "\n",
    "    def query_key_value(self):\n",
    "        self.qlayer = Layer_Dense(self.embd_dim, self.embd_dim,8)\n",
    "        self.klayer = Layer_Dense(self.embd_dim, self.embd_dim,7)\n",
    "        self.vlayer = Layer_Dense(self.embd_dim, self.embd_dim,6)\n",
    "\n",
    "    def residual_connections(self, self_attention_vals, encodings):\n",
    "        self.res = self_attention_vals + encodings\n",
    "        \n",
    "    def dropout_layer(self, X, p=0.1):\n",
    "        assert 0 <= p <= 1\n",
    "        \n",
    "        if p == 0:\n",
    "            return X\n",
    "        \n",
    "        mask = np.random.binomial(1, 1-p, size=X.shape)\n",
    "        return X * mask / (1-p)\n",
    "        \n",
    "\n",
    "class Encoder(Transformer):   \n",
    "    def self_attention(self,ewe,n,apply_dropout=False):\n",
    "        dk = self.embd_dim // self.n_heads\n",
    "        heads = [[]]\n",
    "        \n",
    "        for start in range(0, len(self.embeddings), dk):\n",
    "            for i in range(len(ewe)):\n",
    "                end = start + dk\n",
    "                head = ewe[i][start:end]\n",
    "                heads.append(head)\n",
    "\n",
    "        self.qlayer.forward(ewe)\n",
    "        self.klayer.forward(ewe)\n",
    "        self.vlayer.forward(ewe)\n",
    "        self.qlayer.output -= self.qlayer.biases\n",
    "        self.klayer.output -= self.klayer.biases\n",
    "        self.vlayer.output -= self.vlayer.biases\n",
    "\n",
    "        mul = self.klayer.output.reshape(len(self.input),self.embd_dim, n+2)\n",
    "        self.activation.forward(np.matmul(self.qlayer.output, mul) / sqrt(self.embd_dim))\n",
    "        \n",
    "#         if apply_dropout:\n",
    "#             self.activation.output = self.dropout_layer(self.activation.output, p=0.1) \n",
    "        \n",
    "        # self.activation.forward(np.dot(self.qlayer.output, mul) / sqrt(self.embd_dim))\n",
    "        attention_vals = np.matmul(self.activation.output, self.vlayer.output)\n",
    "        # attention_vals = np.dot(self.activation.output, self.vlayer.output)\n",
    "        \n",
    "        # if apply_dropout:\n",
    "        #     attention_vals = self.dropout_layer(attention_vals, p=0.1)\n",
    "        \n",
    "        self.residual_connections(attention_vals, ewe)\n",
    "\n",
    "    def key_value(self):\n",
    "        self.ed_klayer = Layer_Dense(self.embd_dim, self.embd_dim,5)\n",
    "        self.ed_vlayer = Layer_Dense(self.embd_dim, self.embd_dim,4)\n",
    "\n",
    "    def map(self, input_tokens):\n",
    "        self.input = [[]]\n",
    "        i=0\n",
    "        print(len(input_tokens))\n",
    "        for arr in input_tokens:\n",
    "            # arr.insert(0, self.vocab['sos'])\n",
    "            # arr.append(self.vocab['eos'])\n",
    "            # self.input.append(arr)\n",
    "            for val in arr:\n",
    "                self.input[i].append(val)\n",
    "            self.input.append([])\n",
    "            self.input[i].insert(0, self.vocab['sos'])\n",
    "            self.input[i].append(self.vocab['eos'])\n",
    "            i+=1\n",
    "                \n",
    "class Decoder(Transformer):\n",
    "    \n",
    "    def map(self, input_tokens):\n",
    "        self.input = [[]]\n",
    "        i=0\n",
    "        for arr in input_tokens:\n",
    "            # arr.insert(0, self.vocab['sos'])\n",
    "            # self.input.append(arr)\n",
    "            for val in arr:\n",
    "                self.input[i].append(val)\n",
    "            self.input.append([])\n",
    "            self.input[i].insert(0, self.vocab['sos'])\n",
    "            i+=1\n",
    "\n",
    "    def label(self, input_tokens):\n",
    "        self.label = [[]*len(input_tokens)]\n",
    "        i=0\n",
    "        for arr in input_tokens:\n",
    "            # arr.append(self.vocab['eos'])\n",
    "            # self.label.append(arr)\n",
    "            for val in arr:\n",
    "                self.label[i].append(val)\n",
    "            self.label.append([])\n",
    "            self.label[i].append(self.vocab['eos'])\n",
    "            i+=1\n",
    "\n",
    "    def self_attention(self, dwe, m, gi, apply_dropout=False, flag=0):\n",
    "        if flag == 0:\n",
    "            self.mask = np.array([[-1e300]*(m+1)]*(m+1))\n",
    "            for i in range(m+1):\n",
    "                for j in range(i+1):\n",
    "                    self.mask[i][j] = 0\n",
    "                \n",
    "        # for _ in range(m+1):\n",
    "        self.qlayer.forward(dwe)\n",
    "        self.klayer.forward(dwe)\n",
    "        self.vlayer.forward(dwe)\n",
    "        self.qlayer.output -= self.qlayer.biases\n",
    "        self.klayer.output -= self.klayer.biases\n",
    "        self.vlayer.output -= self.vlayer.biases\n",
    "        \n",
    "        mul = self.klayer.output.reshape(len(self.input), self.embd_dim, m+1)\n",
    "        self.midvalue = np.matmul(self.qlayer.output, mul) / sqrt(self.embd_dim)\n",
    "        # self.midvalue = (np.dot(self.qlayer.output, self.klayer.output.T) / sqrt(self.embd_dim))\n",
    "\n",
    "        if flag == 0:\n",
    "            for arr in self.midvalue:\n",
    "                arr += self.mask\n",
    "        \n",
    "        self.activation.forward(self.midvalue)\n",
    "        \n",
    "        attention_vals = np.matmul(self.activation.output, self.vlayer.output)\n",
    "        # attention_vals = np.dot(self.activation.output, self.vlayer.output)\n",
    "        \n",
    "        # if apply_dropout:\n",
    "        #     attention_vals = self.dropout_layer(attention_vals, p=0.1)\n",
    "        \n",
    "        self.residual_connections(attention_vals, dwe)\n",
    "\n",
    "    def ed_attention(self, n, gi, e, apply_dropout=False):\n",
    "        self.ed_qlayer.forward(self.res)\n",
    "        self.ed_qlayer.output -= self.ed_qlayer.biases        \n",
    "\n",
    "        e.ed_klayer.forward(e.res)\n",
    "        e.ed_vlayer.forward(e.res)\n",
    "        e.ed_klayer.output -= e.ed_klayer.biases\n",
    "        e.ed_klayer.output -= e.ed_klayer.biases\n",
    "\n",
    "        self.activation2 = Activation_Softmax()\n",
    "        mul = e.ed_klayer.output.reshape(len(self.input), self.embd_dim, n+2)\n",
    "        self.activation2.forward(np.matmul(self.ed_qlayer.output, mul) / sqrt(self.embd_dim))\n",
    "        # self.activation2.forward((np.dot(self.ed_qlayer.output, e.ed_klayer.output.T) / sqrt(self.embd_dim)))\n",
    "        \n",
    "        attention_vals = np.matmul(self.activation2.output, e.ed_vlayer.output)\n",
    "        # attention_vals = np.dot(self.activation2.output, e.ed_vlayer.output)\n",
    "\n",
    "        # if apply_dropout:\n",
    "        #     attention_vals = self.dropout_layer(attention_vals, p=0.1)\n",
    "        \n",
    "        self.final_residuals(attention_vals, self.res)\n",
    "\n",
    "    def key_value(self):\n",
    "        self.ed_qlayer = Layer_Dense(self.embd_dim, self.embd_dim ,3)\n",
    "    \n",
    "    def final_residuals(self, ed_residuals, d_embed):\n",
    "        self.final = ed_residuals + d_embed\n",
    "    \n",
    "    def next_word(self, k):\n",
    "        self.nxtlayer = Layer_Dense(self.embd_dim, self.embd_dim * 4, 0)\n",
    "        self.nxtactivation = Activation_ReLU()\n",
    "        self.nxtlayer2 = Layer_Dense(self.embd_dim * 4, self.embd_dim, 1)\n",
    "        self.activation3 = Activation_Softmax()\n",
    "        self.vocablayer = Layer_Dense(self.embd_dim, len(self.vocab), 2)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'heart', 'of', 'the', 'bustling', 'city', ',', 'there', 'was', 'a', 'small', 'café', 'that', 'became', 'a', 'sanctuary', 'for', 'those', 'seeking', 'solace', 'from', 'the', 'chaotic', 'world', 'outside', '.', 'every', 'morning', ',', 'as', 'the', 'sun', 'began', 'to', 'rise', ',', 'the', 'aroma', 'of', 'freshly', 'brewed', 'coffee', 'filled', 'the', 'air', ',', 'inviting', 'passersby', 'to', 'step', 'inside', 'and', 'escape', 'their', 'daily', 'routines', '.', 'the', 'walls', 'were', 'adorned', 'with', 'vibrant', 'art', ',', 'and', 'the', 'soft', 'sound', 'of', 'music', 'created', 'an', 'atmosphere', 'of', 'warmth', 'and', 'comfort', '.', 'patrons', 'often', 'gathered', 'around', 'the', 'wooden', 'tables', ',', 'sharing', 'stories', 'and', 'laughter', 'over', 'delicious', 'pastries', 'and', 'steaming', 'mugs', 'of', 'their', 'favorite', 'beverages', '.', 'it', 'was', 'a', 'place', 'where', 'time', 'seemed', 'to', 'slow', 'down', ',', 'allowing', 'everyone', 'to', 'savor', 'the', 'little', 'moments', 'that', 'made', 'life', 'truly', 'special', '.', 'eos']\n",
      "['en', 'el', 'corazón', 'de', 'la', 'bulliciosa', 'ciudad', ',', 'había', 'un', 'pequeño', 'café', 'que', 'se', 'convirtió', 'en', 'un', 'santuario', 'para', 'aquellos', 'que', 'buscaban', 'consuelo', 'del', 'caótico', 'mundo', 'exterior', '.', 'cada', 'mañana', ',', 'al', 'comenzar', 'a', 'salir', 'el', 'sol', ',', 'el', 'aroma', 'del', 'recién', 'café', 'preparado', 'llenaba', 'el', 'aire', ',', 'invitando', 'a', 'los', 'transeúntes', 'a', 'entrar', 'y', 'escapar', 'de', 'sus', 'rutinas', 'diarias', '.', 'las', 'paredes', 'estaban', 'adornadas', 'con', 'arte', 'vibrante', ',', 'y', 'el', 'suave', 'sonido', 'de', 'la', 'música', 'creaba', 'una', 'atmósfera', 'de', 'calidez', 'y', 'confort', '.', 'los', 'clientes', 'a', 'menudo', 'se', 'reunían', 'alrededor', 'de', 'las', 'mesas', 'de', 'madera', ',', 'compartiendo', 'historias', 'y', 'risas', 'sobre', 'deliciosos', 'pasteles', 'y', 'humeantes', 'tazas', 'de', 'sus', 'bebidas', 'favoritas', '.', 'era', 'un', 'lugar', 'donde', 'el', 'tiempo', 'parecía', 'ralentizarse', ',', 'permitiendo', 'que', 'todos', 'saborearan', 'los', 'pequeños', 'momentos', 'que', 'hacían', 'que', 'la', 'vida', 'fuera', 'realmente', 'especial', '.', 'eos']\n",
      "5\n",
      "[[2, 33, 21, 34, 94], [9, 10, 11, 12, 94], [21, 22, 23, 24, 94], [26, 27, 8, 28, 94], [78, 10, 79, 80, 94], []]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"\"\"In the heart of the bustling city, there was a small café that became a sanctuary for those seeking \"\"\" \n",
    "    \"\"\"solace from the chaotic world outside. Every morning, as the sun began to rise, the aroma of freshly \"\"\"\n",
    "    \"\"\"brewed coffee filled the air, inviting passersby to step inside and escape their daily routines. \"\"\"\n",
    "    \"\"\"The walls were adorned with vibrant art, and the soft sound of music created an atmosphere of warmth \"\"\" \n",
    "    \"\"\"and comfort. Patrons often gathered around the wooden tables, sharing stories and laughter over delicious \"\"\" \n",
    "    \"\"\"pastries and steaming mugs of their favorite beverages. It was a place where time seemed to slow down, \"\"\" \n",
    "    \"\"\"allowing everyone to savor the little moments that made life truly special. \"\"\"\n",
    "]\n",
    "\n",
    "corpus_sp = [\n",
    "    \"\"\"En el corazón de la bulliciosa ciudad, había un pequeño café que se convirtió en un santuario para aquellos \"\"\"\n",
    "    \"\"\"que buscaban consuelo del caótico mundo exterior. Cada mañana, al comenzar a salir el sol, El aroma del recién \"\"\" \n",
    "    \"\"\"café preparado llenaba el aire, invitando a los transeúntes a entrar y escapar de sus rutinas diarias. \"\"\" \n",
    "    \"\"\"Las paredes estaban adornadas con arte vibrante, y el suave sonido de la música creaba una atmósfera de calidez \"\"\" \n",
    "    \"\"\"y confort. Los clientes a menudo se reunían alrededor de las mesas de madera, compartiendo historias y risas \"\"\" \n",
    "    \"\"\"sobre deliciosos pasteles y humeantes tazas de sus bebidas favoritas. Era un lugar donde el tiempo parecía \"\"\" \n",
    "    \"\"\"ralentizarse, permitiendo que todos saborearan los pequeños momentos que hacían que la vida fuera realmente especial. \"\"\"\n",
    "]\n",
    "\n",
    "corpus[0] += ' eos'\n",
    "corpus_sp[0] += ' eos'\n",
    "\n",
    "corpus[0]\n",
    "\n",
    "e = Encoder(corpus, 4)\n",
    "d = Decoder(corpus_sp, 4)\n",
    "\n",
    "e_embd = []\n",
    "# The aroma of freshly\n",
    "# El aroma del recién\n",
    "\n",
    "# Every morning, as the sun began to rise, the aroma of freshly brewed coffee filled the air, inviting passersby to step inside and escape their daily routines.\n",
    "# Cada mañana, al comenzar a salir el sol, El aroma del recién café preparado llenaba el aire, invitando a los transeúntes a entrar y escapar de sus rutinas diarias.\n",
    "\n",
    "# In the heart of the bustling city\n",
    "# En el corazón de la bulliciosa ciudad\n",
    "\n",
    "# input = [\"Every morning, as the sun began to rise, the aroma of freshly brewed coffee filled the air, inviting passersby to step inside and escape their daily routines.\"]\n",
    "# input = [\"In the heart of the bustling city\"]\n",
    "# \"heart of the bustling\"\n",
    "# ,\"The aroma of freshly\",\"The aroma of freshly\",\"The aroma of freshly\",\"The aroma of freshly\"\n",
    "\n",
    "e.vocab_creation()\n",
    "inputs = [\"The aroma of freshly\",\"there was a small\", \"the chaotic world outside\",\"Every morning , as\", \"It was a place\"]\n",
    "tokenized_input = [[e.vocab[token] for token in sentence.lower().split()] for sentence in inputs]\n",
    "n = len(tokenized_input[0])\n",
    "\n",
    "# tokenized_input = [word_tokenize(sentence.lower()) for sentence in inputs]\n",
    "# In the heart of the bustling city\n",
    "# En el corazón de la bulliciosa ciudad\n",
    "# ,\"El aroma del recién\",\"El aroma del recién\",\"El aroma del recién\",\"El aroma del recién\"]\n",
    "\n",
    "d.vocab_creation()\n",
    "decoder_inputs = [\"El aroma del recién\",\"había un pequeño café\",\"del caótico mundo exterior\",\"Cada mañana , al\",\"Era un lugar donde\"]\n",
    "d_tokenized_input = [[d.vocab[token] for token in sentence.lower().split()] for sentence in decoder_inputs]\n",
    "m = len(d_tokenized_input[0])\n",
    "\n",
    "# decoder_input = [\"Cada mañana, al comenzar a salir el sol, El aroma del recién café preparado llenaba el aire, invitando a los transeúntes a entrar y escapar de sus rutinas diarias.\"]\n",
    "# decoder_input = [\"En el corazón de la bulliciosa ciudad\"]\n",
    "# d_tokenized_input = [word_tokenize(sentence.lower()) for sentence in decoder_inputs]\n",
    "\n",
    "gi = 0\n",
    "\n",
    "e.word_embeddings()\n",
    "e.positional_encoding(n+2)\n",
    "e.query_key_value()\n",
    "e.feed_forward()\n",
    "e.key_value()\n",
    "\n",
    "d.word_embeddings()\n",
    "d.positional_encoding(m+1)\n",
    "d.query_key_value()\n",
    "d.feed_forward()\n",
    "d.key_value()\n",
    "d.next_word(m)\n",
    "\n",
    "e.map(tokenized_input)\n",
    "d.map(d_tokenized_input)\n",
    "d.label(d_tokenized_input)\n",
    "print(d.label)\n",
    "loss_fn = Loss_CrossCategoricalEntropy()\n",
    "y_train = []\n",
    "for label in d.label :\n",
    "    y_train.append(d.one_hot(np.array(label), len(d.vocab)-1))\n",
    "\n",
    "optimizer = OptimizerAdam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 95), dtype=float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.input.pop()\n",
    "d.input.pop()\n",
    "d.label.pop()\n",
    "y_train.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[ 7 42 63 78 42]\n",
      " [75 54 42 13 56]\n",
      " [42 42 42 42 54]\n",
      " [42 33  7 21 82]\n",
      " [56 78 42 42 54]]\n",
      "loss :  5.336473241190306\n",
      "23\n",
      "[[80 78 80 78 80]\n",
      " [79 78 54 21 21]\n",
      " [80 78 47 80 21]\n",
      " [21 58 21 21 21]\n",
      " [21 79 78 78  7]]\n",
      "loss :  5.5902328559183205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3336/493081648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aryan\\bp.project\\PlatformComponents\\Entities\\MPNeuronInfo.py\u001b[0m in \u001b[0;36mupdate_params\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_w\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_w\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdweights\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_b\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbiases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_len = len(d_tokenized_input[0])\n",
    "max_len += 1\n",
    "warmup_steps = 5\n",
    "f=0\n",
    "flag = 0\n",
    "iterate = 0\n",
    "curr_loss = 0\n",
    "prev_loss = 0\n",
    "diff = 0\n",
    "decay_factor = 0.8\n",
    "decay_count = 0\n",
    "decay_flag = 0\n",
    "decay_bias = 0\n",
    "lrate = 0.0005\n",
    "\n",
    "for i in range(200):\n",
    "    gi = 0\n",
    "    count = 0\n",
    "    while count != max_len :\n",
    "        count += 1\n",
    "        iterate = count + max_len*i + 1\n",
    "        print(iterate)\n",
    "            \n",
    "        lrate = (d.embd_dim ** -0.5) * min(iterate ** -0.5, iterate * (warmup_steps ** -1.5))*0.025\n",
    "        if prev_loss != 0 and prev_loss < curr_loss :\n",
    "                lrate *= 0.5            \n",
    "\n",
    "        optimizer.learning_rate = lrate\n",
    "\n",
    "        # ewe = e.embeddings[(np.array(e.input)).tolist()]\n",
    "        # ewe += e.position_encodings\n",
    "        \n",
    "        ewe = []\n",
    "        for i,arr in enumerate(e.input):\n",
    "            ewe.append(e.embeddings[arr])\n",
    "            ewe[i] += e.position_encodings\n",
    "        # ewe = e.dropout_layer(np.array(ewe), p=0.1)\n",
    "        \n",
    "        dwe = []        \n",
    "        for i,arr in enumerate(d.input):\n",
    "            dwe.append(d.embeddings[arr])\n",
    "            dwe[i] += d.position_encodings\n",
    "        # dwe = d.dropout_layer(np.array(dwe), p=0.1)\n",
    "\n",
    "        e.self_attention(ewe, n)\n",
    "        e.res = e.layer_normalization(e.res)\n",
    "        \n",
    "        e.ffn1.forward(e.res)\n",
    "        e.ffnact.forward(e.ffn1.output)\n",
    "        e.ffn2.forward(e.ffnact.output)\n",
    "        # e.ffn2.output = e.dropout_layer(e.ffn2.output, p=0.1)\n",
    "        e.res += e.ffn2.output\n",
    "        e.res = e.layer_normalization(e.res)\n",
    "\n",
    "        # dwe = d.embeddings[(np.array(d.input)).tolist()]\n",
    "        # dwe += d.position_encodings\n",
    "\n",
    "        d.self_attention(dwe, m, gi)\n",
    "        d.res = d.layer_normalization(d.res)\n",
    "\n",
    "        d.ed_attention(n, gi, e)\n",
    "        d.final = d.layer_normalization(d.final)\n",
    "\n",
    "        d.nxtlayer.forward(d.final)\n",
    "        d.nxtactivation.forward(d.nxtlayer.output)\n",
    "        d.nxtlayer2.forward(d.nxtactivation.output)\n",
    "        # d.nxtlayer2.output = d.dropout_layer(d.nxtlayer2.output, p=0.1)\n",
    "        d.nxtlayer2.output += d.final\n",
    "        d.nxtlayer2.output = d.layer_normalization(d.nxtlayer2.output)\n",
    "        \n",
    "        d.vocablayer.forward(d.nxtlayer2.output)\n",
    "        d.activation3.forward(d.vocablayer.output)\n",
    "\n",
    "        check = np.argmax(d.activation3.output, axis=2)\n",
    "\n",
    "        print(check)\n",
    "\n",
    "        # if gi == m :\n",
    "        #     gi = 0\n",
    "        # else:\n",
    "        # for key, val in d.vocab.items():\n",
    "        #     for some in check :\n",
    "        #         if val == some:\n",
    "        #             result.append(key)\n",
    "\n",
    "        gi += 1\n",
    "\n",
    "        loss_fn.d3_backward(d.activation3.output, np.array(y_train))\n",
    "        \n",
    "        d.activation3.d3_backward(loss_fn.dinputs)\n",
    "        d.vocablayer.d3_backward(d.activation3.dinputs)\n",
    "        d.nxtlayer2.d3_backward(d.vocablayer.dinputs)\n",
    "        d.nxtactivation.d3_backward(d.nxtlayer2.dinputs)\n",
    "        d.nxtlayer.d3_backward(d.nxtactivation.dinputs)\n",
    "\n",
    "        prev_loss = curr_loss       \n",
    "        curr_loss = loss_fn.d3_forward(d.activation3.output, np.array(y_train))\n",
    "\n",
    "        print(\"loss : \",curr_loss)\n",
    "\n",
    "        # encoder decoder attention layer\n",
    "        mul = np.transpose(d.activation2.output, (0,2,1)) \n",
    "        ed_v_new_dvals = np.matmul(mul, d.nxtlayer.dinputs)\n",
    "        e.ed_vlayer.d3_backward(ed_v_new_dvals)\n",
    "\n",
    "        mul = np.transpose(e.ed_vlayer.output, (0,2,1)) \n",
    "        ed_softmax_dvals = np.matmul(d.nxtlayer.dinputs, mul)\n",
    "        d.activation2.d3_backward(ed_softmax_dvals)\n",
    "\n",
    "        ed_q_new_dvals = np.matmul(d.activation2.dinputs, e.ed_klayer.output)\n",
    "        d.ed_qlayer.d3_backward(ed_q_new_dvals)\n",
    "\n",
    "        mul = np.transpose(d.activation2.dinputs, (0,2,1)) \n",
    "        ed_k_new_dvals = np.matmul(mul, d.ed_qlayer.output)\n",
    "        e.ed_klayer.d3_backward(ed_k_new_dvals)\n",
    "\n",
    "        # decoder attention layer\n",
    "        mul = np.transpose(d.activation.output, (0,2,1)) \n",
    "        d_v_new_dvals = np.matmul(mul, d.ed_qlayer.dinputs)\n",
    "        d.vlayer.d3_backward(d_v_new_dvals)\n",
    "\n",
    "        mul = np.transpose(d.vlayer.output, (0,2,1)) \n",
    "        d_softmax_dvals = np.matmul(d.ed_qlayer.dinputs, mul)\n",
    "        d.activation.d3_backward(d_softmax_dvals)\n",
    "\n",
    "        d_q_new_dvals = np.matmul(d.activation.dinputs, d.klayer.output)\n",
    "        d.qlayer.d3_backward(d_q_new_dvals)\n",
    "\n",
    "        d_k_new_dvals = np.matmul(d.activation.dinputs, d.qlayer.output)\n",
    "        d.klayer.d3_backward(d_k_new_dvals)\n",
    "\n",
    "        # encoder attention layer\n",
    "        encoder_dinputs = e.ed_vlayer.dinputs + e.ed_klayer.dinputs\n",
    "\n",
    "        e.ffn2.d3_backward(encoder_dinputs)\n",
    "        e.ffnact.d3_backward(e.ffn2.dinputs)\n",
    "        e.ffn1.d3_backward(e.ffnact.dinputs)\n",
    "\n",
    "        mul = np.transpose(e.activation.output, (0,2,1)) \n",
    "        e_v_new_dvals = np.matmul(mul, encoder_dinputs)\n",
    "        e.vlayer.d3_backward(e_v_new_dvals)\n",
    "\n",
    "        mul = np.transpose(e.vlayer.output, (0,2,1)) \n",
    "        e_softmax_dvals = np.matmul(encoder_dinputs, mul)\n",
    "        e.activation.d3_backward(e_softmax_dvals)\n",
    "\n",
    "        e_q_new_dvals = np.matmul(e.activation.dinputs, e.klayer.output)\n",
    "        e.qlayer.d3_backward(e_q_new_dvals)\n",
    "        \n",
    "        e_k_new_dvals = np.matmul(e.activation.dinputs, e.qlayer.output)\n",
    "        e.klayer.d3_backward(e_k_new_dvals)\n",
    "\n",
    "        optimizer.update_params(d.vocablayer)\n",
    "        optimizer.update_params(d.nxtlayer2)\n",
    "        optimizer.update_params(d.nxtlayer)\n",
    "\n",
    "        optimizer.update_params(e.ed_vlayer)\n",
    "        optimizer.update_params(e.ed_klayer)\n",
    "        optimizer.update_params(d.ed_qlayer)\n",
    "\n",
    "        optimizer.update_params(d.vlayer)\n",
    "        optimizer.update_params(d.klayer)\n",
    "        optimizer.update_params(d.qlayer)\n",
    "        \n",
    "        optimizer.update_params(e.ffn2)\n",
    "        optimizer.update_params(e.ffn1)\n",
    "\n",
    "        optimizer.update_params(e.vlayer)\n",
    "        optimizer.update_params(e.klayer)\n",
    "        optimizer.update_params(e.qlayer)\n",
    "\n",
    "#         if curr_loss < 0.01 :\n",
    "#             f=1             \n",
    "#             break\n",
    "#        if count == 2:\n",
    "#             break\n",
    "#     if f==1 :\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "weights_arr = [e.qlayer.weights, e.klayer.weights, e.vlayer.weights, d.qlayer.weights, d.klayer.weights, d.vlayer.weights,\n",
    "               d.ed_qlayer.weights, e.ed_klayer.weights, e.ed_vlayer.weights, e.ffn1.weights, e.ffn1.biases, e.ffn2.weights, \n",
    "               e.ffn2.biases, d.nxtlayer.weights, d.nxtlayer.biases, d.nxtlayer2.weights, d.nxtlayer2.biases,\n",
    "               d.vocablayer.weights, d.vocablayer.biases]\n",
    "\n",
    "keys = ['eq','ek','ev','dq','dk','dv','edq','edk','edv','effn1_w','effn1_b','effn2_w','effn2_b','dffn1_w','dffn1_b','dffn2_w',\n",
    "        'dffn2_b','vocab_w','vocab_b']\n",
    "json_dict = {}\n",
    "\n",
    "for i,key in enumerate(keys):\n",
    "    json_dict[key] = weights_arr[i].tolist()\n",
    "    \n",
    "with open('model_weights.json','w') as json_file:\n",
    "    json.dump(json_dict, json_file, indent=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 33, 21, 34, 94]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 32, 4, 33, 93]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[' del del del del del ', ' del del del del del ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan\\AppData\\Local\\Temp/ipykernel_3336/2879488812.py:36: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  dwe.append(d.embeddings[arr])\n"
     ]
    }
   ],
   "source": [
    "gi = d.vocab['sos']\n",
    "d.input = [[gi],[gi]]\n",
    "inputs = [\"The aroma of freshly\",\"there was a small\"]\n",
    "tokenized_input = [[e.vocab[token] for token in sentence.lower().split()] for sentence in inputs]\n",
    "n = len(tokenized_input[0])\n",
    "m = 0\n",
    "apply_dropout = False\n",
    "e.map(tokenized_input)\n",
    "e.input.pop()\n",
    "ewe = []\n",
    "for i,arr in enumerate(e.input):\n",
    "    ewe.append(e.embeddings[arr])\n",
    "    ewe[i] += e.position_encodings\n",
    "e.self_attention(ewe, n, apply_dropout)\n",
    "e.res = e.layer_normalization(e.res)\n",
    "e.ffn1.forward(e.res)\n",
    "e.ffnact.forward(e.ffn1.output)\n",
    "e.ffn2.forward(e.ffnact.output)\n",
    "\n",
    "e.res += e.ffn2.output\n",
    "e.res = e.layer_normalization(e.res)\n",
    "flag = 1\n",
    "translated_output= []\n",
    "\n",
    "for j in range(max_len):\n",
    "    translated_output.append([])\n",
    "    dwe = []        \n",
    "    for i,arr in enumerate(d.input):\n",
    "        dwe.append(d.embeddings[arr])\n",
    "        dwe[i] += d.position_encodings[j]\n",
    "    d.self_attention(dwe, m, gi, apply_dropout, flag)\n",
    "    d.res = d.layer_normalization(d.res)\n",
    "\n",
    "    d.ed_attention(n, gi, e, apply_dropout)\n",
    "    d.final = d.layer_normalization(d.final)\n",
    "\n",
    "    d.nxtlayer.forward(d.final)\n",
    "    d.nxtactivation.forward(d.nxtlayer.output)\n",
    "    d.nxtlayer2.forward(d.nxtactivation.output)\n",
    "\n",
    "    d.nxtlayer2.output += d.final\n",
    "    d.nxtlayer2.output = d.layer_normalization(d.nxtlayer2.output)\n",
    "    \n",
    "    d.vocablayer.forward(d.nxtlayer2.output)\n",
    "    d.activation3.forward(d.vocablayer.output)\n",
    "\n",
    "    check = np.argmax(d.activation3.output, axis=2)\n",
    "\n",
    "    gi = check\n",
    "    d.input = [[gi[0]],gi[1]]\n",
    "    \n",
    "    for ans in check:\n",
    "        for key, val in d.vocab.items():\n",
    "            if val == ans:\n",
    "                translated_output[j].append(key)\n",
    "                \n",
    "translations = np.transpose(translated_output, (1,0))\n",
    "k = translations.tolist()\n",
    "sen = \" \"\n",
    "for i,sentence in enumerate(k):\n",
    "    for token in sentence:\n",
    "        sen += token\n",
    "        sen += \" \"\n",
    "    k[i] = sen\n",
    "    sen = \" \"\n",
    "\n",
    "print(k)\n",
    "# Cada mañana, al comenzar a salir el sol, El aroma del recién café preparado llenaba el aire, invitando a los transeúntes a entrar y escapar de sus rutinas diarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The aroma of freshly',\n",
       " 'there was a small',\n",
       " 'the chaotic world outside',\n",
       " 'Every morning , as',\n",
       " 'It was a place')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The aroma of freshly\",\"there was a small\", \"the chaotic world outside\",\"Every morning , as\", \"It was a place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"El aroma del recién\",\"había un pequeño café\",\"del caótico mundo exterior\",\"Cada mañana , al\",\"Era un lugar donde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-7.85937018e-01, -6.34515843e-01, -5.50710896e-01,\n",
       "         -8.51902686e-01, -2.86224936e-01, -9.31353143e-01,\n",
       "         -9.89046769e-02, -9.93260467e-01,  1.82017336e-01,\n",
       "         -9.55617939e-01,  3.71324908e-01, -9.18628342e-01,\n",
       "          5.28193471e-01, -8.63826493e-01,  6.34522581e-01,\n",
       "         -7.50339574e-01,  7.71559730e-01, -6.30184719e-01,\n",
       "          8.38921728e-01, -4.66002426e-01,  9.00627893e-01,\n",
       "         -4.00272960e-01,  9.58754927e-01, -2.46201249e-01,\n",
       "          9.59297931e-01, -1.12587505e-01,  9.76563491e-01,\n",
       "         -4.48434443e-03,  9.61473686e-01,  1.18479763e-01,\n",
       "          9.92211693e-01,  2.09880965e-01,  9.29493327e-01,\n",
       "          2.93449248e-01,  9.54750155e-01,  4.00182150e-01,\n",
       "          8.49854437e-01,  4.42655550e-01,  8.62171271e-01,\n",
       "          5.33340360e-01,  7.70704544e-01,  6.03180684e-01,\n",
       "          7.34139350e-01,  6.02442166e-01,  7.47649575e-01,\n",
       "          6.65886379e-01,  7.07859050e-01,  7.61143595e-01,\n",
       "          6.37168705e-01,  7.98678042e-01,  6.22182027e-01,\n",
       "          8.32333924e-01,  6.02958699e-01,  7.75974990e-01,\n",
       "          5.27523807e-01,  8.69022816e-01,  5.33206724e-01,\n",
       "          8.99428284e-01,  5.06818557e-01,  9.14908493e-01,\n",
       "          4.02348667e-01,  9.14381505e-01,  3.94539548e-01,\n",
       "          9.24676188e-01,  4.16268535e-01,  9.40473884e-01,\n",
       "          3.96792003e-01,  9.38095474e-01,  3.33957612e-01,\n",
       "          9.65935347e-01,  2.91875378e-01,  9.48617236e-01,\n",
       "          3.37198306e-01,  9.31008433e-01,  2.92259043e-01,\n",
       "          9.25549828e-01,  3.00053841e-01,  1.00250548e+00,\n",
       "          2.45100600e-01,  9.93650671e-01,  2.29353017e-01,\n",
       "          9.46190540e-01,  2.01565928e-01,  1.00664802e+00,\n",
       "          1.73174538e-01,  9.63409607e-01,  2.02070848e-01,\n",
       "          9.95558228e-01,  1.59609363e-01,  9.73090574e-01,\n",
       "          1.82804853e-01,  9.62310441e-01,  1.31211704e-01,\n",
       "          9.60611324e-01,  1.16882871e-01,  9.52874007e-01,\n",
       "          1.06361661e-01,  9.54239822e-01,  1.23724187e-01,\n",
       "          9.54987443e-01,  6.53015837e-02,  9.57953285e-01,\n",
       "          7.17793184e-02,  1.02436752e+00,  1.11412882e-01,\n",
       "          9.97207702e-01,  7.50413583e-02,  9.63375433e-01,\n",
       "          8.45394105e-02,  9.98726587e-01,  7.72955145e-02,\n",
       "          1.00064955e+00,  7.46009702e-02,  9.97313608e-01,\n",
       "          3.06787804e-02,  9.71796444e-01,  2.45904334e-02,\n",
       "          9.92417321e-01,  6.53737116e-02,  1.03116566e+00,\n",
       "          4.45373359e-02,  9.88252069e-01,  9.15562124e-02,\n",
       "          9.99140061e-01,  3.55210355e-02,  1.03684308e+00,\n",
       "          5.48500853e-02,  9.75272996e-01,  6.91072905e-02,\n",
       "          1.01920265e+00,  5.97540862e-03,  9.97857974e-01,\n",
       "          3.83684204e-02,  1.02476606e+00,  2.47061730e-02,\n",
       "          9.87045767e-01,  3.76783894e-02,  1.00333704e+00,\n",
       "          3.32223977e-02,  9.87857647e-01, -6.11111236e-04,\n",
       "          1.03201657e+00,  5.77717037e-02,  1.03640481e+00,\n",
       "         -1.56084575e-02,  1.01132872e+00,  5.12076334e-03,\n",
       "          1.04217005e+00,  3.24377121e-02,  1.02045243e+00,\n",
       "          2.87243471e-02,  1.02891415e+00, -8.61594378e-03,\n",
       "          1.03485083e+00,  4.93187455e-03,  9.79679592e-01,\n",
       "          5.55392164e-03,  1.04285386e+00, -1.68020801e-02,\n",
       "          9.90207122e-01,  4.35693162e-02,  9.99757704e-01,\n",
       "         -1.61403918e-02,  9.71676783e-01,  5.05928972e-02,\n",
       "          1.02834948e+00,  3.14115582e-02,  9.85608802e-01,\n",
       "         -3.14321935e-02,  1.01668977e+00,  4.04635869e-02,\n",
       "          9.74988018e-01, -2.66243691e-02,  9.86806207e-01,\n",
       "         -1.42476662e-02,  9.89739151e-01, -1.59642461e-03,\n",
       "          9.76719130e-01,  4.84712514e-02,  9.58909619e-01,\n",
       "          2.59675915e-02,  1.02393818e+00, -4.58830929e-04,\n",
       "          1.03968270e+00,  4.90131365e-02,  9.75762257e-01,\n",
       "         -2.17226318e-02,  9.70155193e-01, -3.02576137e-02,\n",
       "          9.86504444e-01, -2.04089918e-02,  9.63050767e-01,\n",
       "          7.44158640e-03,  1.01321554e+00,  3.20662723e-02,\n",
       "          9.88340209e-01, -1.62898085e-02,  1.00541909e+00,\n",
       "          4.91684972e-03,  1.03581317e+00,  3.71195780e-03,\n",
       "          1.03191075e+00, -3.37699397e-02,  1.03718058e+00,\n",
       "         -5.64334761e-03,  1.03856215e+00, -3.12772650e-02,\n",
       "          1.00784455e+00,  6.88131885e-03,  1.00012130e+00,\n",
       "         -2.04665142e-02,  9.59154091e-01, -3.02229207e-02,\n",
       "          9.64882437e-01,  1.02114576e-02,  1.00211915e+00,\n",
       "         -6.16674198e-03,  1.03155174e+00, -9.45534762e-03,\n",
       "          9.94115873e-01, -3.79451849e-02,  9.56035964e-01,\n",
       "          4.09708457e-02,  9.74508957e-01, -2.68548897e-02,\n",
       "          1.02291175e+00,  3.05768987e-02,  9.69756394e-01,\n",
       "          5.37620196e-03,  9.73431910e-01,  8.25117377e-03,\n",
       "          9.81081343e-01, -1.42284518e-02,  1.00959238e+00,\n",
       "          3.91169737e-02,  1.02976567e+00, -4.19545488e-02,\n",
       "          9.75151040e-01,  3.56219058e-02,  1.00881544e+00,\n",
       "         -1.81837211e-02,  1.00261747e+00,  4.26642985e-02,\n",
       "          9.95178858e-01, -4.11557868e-02,  1.00708074e+00,\n",
       "          2.81752999e-02,  1.02777627e+00,  1.86507055e-02,\n",
       "          9.74920391e-01, -1.22521749e-03,  9.99804005e-01,\n",
       "          2.06210362e-02,  9.64468122e-01, -3.50528880e-02,\n",
       "          1.00123485e+00, -3.76673576e-02,  1.02563382e+00,\n",
       "         -1.48621228e-03,  1.04409309e+00, -2.30929308e-02,\n",
       "          9.97809171e-01,  3.45648126e-02,  9.82027332e-01,\n",
       "         -2.19560070e-02,  1.00712728e+00,  1.20277204e-02,\n",
       "          9.88714542e-01,  2.87149788e-02,  9.66030115e-01,\n",
       "          1.53079090e-02,  1.00223479e+00,  3.88254623e-02,\n",
       "          1.02635110e+00,  3.03320542e-02,  1.03471067e+00,\n",
       "         -4.19040220e-02,  1.04221938e+00, -3.42781923e-02,\n",
       "          9.88220644e-01, -2.15416148e-02,  9.78175395e-01,\n",
       "         -3.51627922e-02,  9.65533127e-01, -2.01107067e-02,\n",
       "          9.94341218e-01, -2.25059145e-02,  1.02715301e+00,\n",
       "         -4.20899498e-02,  9.76691339e-01,  4.18012320e-02,\n",
       "          1.03103893e+00,  3.41581528e-02,  1.01867077e+00,\n",
       "          2.34515047e-03,  9.73549681e-01,  2.66340300e-02,\n",
       "          1.01169075e+00,  3.41337903e-02,  1.02824771e+00,\n",
       "          3.52441161e-02,  1.03826894e+00, -4.35799261e-02,\n",
       "          9.70071278e-01,  5.89096229e-03,  1.02856316e+00,\n",
       "          3.27134524e-02,  1.02429100e+00,  3.39476000e-02,\n",
       "          9.77384357e-01,  2.92770062e-02,  9.81780890e-01,\n",
       "         -3.98860270e-02,  1.04039283e+00,  5.97605273e-03,\n",
       "          9.87754647e-01, -1.08940387e-02,  9.81307116e-01,\n",
       "          2.13465343e-02,  1.01940294e+00, -1.16539421e-02,\n",
       "          9.67627466e-01, -1.57265467e-02,  9.98714663e-01,\n",
       "          2.69560619e-02,  9.87403996e-01, -3.12575607e-04,\n",
       "          1.00386441e+00, -3.13761973e-02,  1.00913292e+00,\n",
       "         -6.26187303e-03,  1.01230764e+00,  2.12828819e-02,\n",
       "          9.93989946e-01, -1.22593928e-02,  1.03437423e+00,\n",
       "          2.21741581e-02,  1.02957991e+00,  2.00592415e-02,\n",
       "          1.03834191e+00,  3.29701773e-02,  9.95322839e-01,\n",
       "          3.87722194e-02,  1.02018004e+00,  2.40363542e-02,\n",
       "          9.93811851e-01, -8.98441174e-03,  9.80415256e-01,\n",
       "         -3.75470332e-02,  1.01336377e+00,  3.93098129e-02,\n",
       "          1.03957281e+00, -8.68162736e-03,  1.02689896e+00,\n",
       "          1.66133355e-02,  9.80945705e-01,  8.93763249e-03,\n",
       "          9.75859560e-01,  3.63905178e-02,  1.02404673e+00,\n",
       "          1.41752046e-02,  1.01812779e+00,  3.83133396e-02,\n",
       "          1.03216384e+00, -3.70111061e-03,  9.68617325e-01,\n",
       "          3.69968033e-02,  1.03204296e+00,  7.75907299e-03,\n",
       "          9.93997998e-01, -2.59945408e-02,  9.79924134e-01,\n",
       "          3.82545591e-02,  9.86090445e-01, -2.80995119e-02,\n",
       "          1.04362535e+00,  3.40423361e-02,  1.04023622e+00,\n",
       "          5.03823951e-03,  9.63175284e-01,  3.72587164e-02,\n",
       "          9.83644935e-01,  2.54761230e-02,  1.01958410e+00,\n",
       "          4.29030196e-02,  9.58979523e-01,  4.08273547e-02,\n",
       "          9.58983604e-01, -3.05037870e-02,  9.59651397e-01,\n",
       "         -2.45276886e-02,  1.03260065e+00,  4.04745978e-02,\n",
       "          9.85260997e-01,  1.65137046e-02,  9.84038288e-01,\n",
       "          3.48062059e-02,  1.02586166e+00,  1.77182118e-04,\n",
       "          9.84030452e-01, -3.20282571e-02,  1.02098876e+00,\n",
       "          6.46457814e-03,  9.88581951e-01,  3.46576445e-02,\n",
       "          9.82100494e-01, -4.05193661e-02,  9.90067014e-01,\n",
       "          5.76081901e-04,  9.70673917e-01, -2.43334332e-02,\n",
       "          9.62452029e-01,  4.09367348e-02,  1.03272707e+00,\n",
       "         -1.32678381e-03,  1.03255364e+00,  3.51659480e-02,\n",
       "          9.96439964e-01,  2.93391663e-02,  1.01672481e+00,\n",
       "          2.24867894e-02,  1.03208768e+00, -2.10961362e-02,\n",
       "          9.90445874e-01,  3.94838484e-03,  1.01881524e+00,\n",
       "          1.46032471e-02,  1.02257967e+00,  2.03310769e-02,\n",
       "          9.62777328e-01, -1.41178477e-02,  9.67947419e-01,\n",
       "          4.27614655e-02,  1.02209129e+00,  7.08978817e-04,\n",
       "          1.01830445e+00, -3.38528259e-02,  9.72227980e-01,\n",
       "          1.36817260e-02,  1.02909218e+00,  1.75503771e-02,\n",
       "          1.02667159e+00, -8.84278304e-03,  9.85160039e-01,\n",
       "          9.09034532e-04,  9.85944183e-01, -2.42237242e-02,\n",
       "          9.65544601e-01,  2.90650380e-02,  9.95202289e-01,\n",
       "         -8.31297510e-03,  9.65504743e-01,  4.12999800e-02,\n",
       "          1.00379507e+00,  7.76370795e-03,  1.01091331e+00,\n",
       "         -3.26771211e-02,  1.00724884e+00,  1.31859879e-02,\n",
       "          9.62115810e-01,  2.17486645e-02,  1.01067170e+00,\n",
       "          3.30697680e-02,  1.02224099e+00, -1.34162180e-02,\n",
       "          9.68365213e-01,  3.13727692e-02,  1.00840327e+00,\n",
       "          2.30560408e-02,  1.02824120e+00,  8.49333561e-03,\n",
       "          9.72926903e-01, -8.19607013e-06,  1.03660358e+00,\n",
       "         -2.70657589e-02,  1.04162740e+00, -3.16653423e-02,\n",
       "          1.01872269e+00,  9.48915313e-03,  1.03287643e+00,\n",
       "         -2.16397264e-02,  9.79891359e-01, -2.69788308e-02,\n",
       "          1.01458668e+00, -1.99395355e-02,  1.03770279e+00,\n",
       "         -1.90517342e-02,  9.59791630e-01, -2.12100024e-02,\n",
       "          1.02834325e+00, -2.80777550e-02,  9.76682087e-01,\n",
       "         -3.23110854e-02,  1.02651516e+00,  1.49093002e-02,\n",
       "          1.01248110e+00, -1.38663013e-02,  1.02668368e+00,\n",
       "         -2.71894348e-02,  9.91159804e-01, -2.63856990e-02,\n",
       "          9.95515773e-01, -8.83604923e-03,  1.03756131e+00,\n",
       "          2.68055046e-04,  9.62091017e-01, -2.40896033e-02,\n",
       "          9.69666953e-01,  1.16954687e-02,  1.04166059e+00,\n",
       "         -2.57917578e-02,  1.03652074e+00]]),\n",
       " array([[-7.85937018e-01, -6.34515843e-01, -5.50710896e-01,\n",
       "         -8.51902686e-01, -2.86224936e-01, -9.31353143e-01,\n",
       "         -9.89046769e-02, -9.93260467e-01,  1.82017336e-01,\n",
       "         -9.55617939e-01,  3.71324908e-01, -9.18628342e-01,\n",
       "          5.28193471e-01, -8.63826493e-01,  6.34522581e-01,\n",
       "         -7.50339574e-01,  7.71559730e-01, -6.30184719e-01,\n",
       "          8.38921728e-01, -4.66002426e-01,  9.00627893e-01,\n",
       "         -4.00272960e-01,  9.58754927e-01, -2.46201249e-01,\n",
       "          9.59297931e-01, -1.12587505e-01,  9.76563491e-01,\n",
       "         -4.48434443e-03,  9.61473686e-01,  1.18479763e-01,\n",
       "          9.92211693e-01,  2.09880965e-01,  9.29493327e-01,\n",
       "          2.93449248e-01,  9.54750155e-01,  4.00182150e-01,\n",
       "          8.49854437e-01,  4.42655550e-01,  8.62171271e-01,\n",
       "          5.33340360e-01,  7.70704544e-01,  6.03180684e-01,\n",
       "          7.34139350e-01,  6.02442166e-01,  7.47649575e-01,\n",
       "          6.65886379e-01,  7.07859050e-01,  7.61143595e-01,\n",
       "          6.37168705e-01,  7.98678042e-01,  6.22182027e-01,\n",
       "          8.32333924e-01,  6.02958699e-01,  7.75974990e-01,\n",
       "          5.27523807e-01,  8.69022816e-01,  5.33206724e-01,\n",
       "          8.99428284e-01,  5.06818557e-01,  9.14908493e-01,\n",
       "          4.02348667e-01,  9.14381505e-01,  3.94539548e-01,\n",
       "          9.24676188e-01,  4.16268535e-01,  9.40473884e-01,\n",
       "          3.96792003e-01,  9.38095474e-01,  3.33957612e-01,\n",
       "          9.65935347e-01,  2.91875378e-01,  9.48617236e-01,\n",
       "          3.37198306e-01,  9.31008433e-01,  2.92259043e-01,\n",
       "          9.25549828e-01,  3.00053841e-01,  1.00250548e+00,\n",
       "          2.45100600e-01,  9.93650671e-01,  2.29353017e-01,\n",
       "          9.46190540e-01,  2.01565928e-01,  1.00664802e+00,\n",
       "          1.73174538e-01,  9.63409607e-01,  2.02070848e-01,\n",
       "          9.95558228e-01,  1.59609363e-01,  9.73090574e-01,\n",
       "          1.82804853e-01,  9.62310441e-01,  1.31211704e-01,\n",
       "          9.60611324e-01,  1.16882871e-01,  9.52874007e-01,\n",
       "          1.06361661e-01,  9.54239822e-01,  1.23724187e-01,\n",
       "          9.54987443e-01,  6.53015837e-02,  9.57953285e-01,\n",
       "          7.17793184e-02,  1.02436752e+00,  1.11412882e-01,\n",
       "          9.97207702e-01,  7.50413583e-02,  9.63375433e-01,\n",
       "          8.45394105e-02,  9.98726587e-01,  7.72955145e-02,\n",
       "          1.00064955e+00,  7.46009702e-02,  9.97313608e-01,\n",
       "          3.06787804e-02,  9.71796444e-01,  2.45904334e-02,\n",
       "          9.92417321e-01,  6.53737116e-02,  1.03116566e+00,\n",
       "          4.45373359e-02,  9.88252069e-01,  9.15562124e-02,\n",
       "          9.99140061e-01,  3.55210355e-02,  1.03684308e+00,\n",
       "          5.48500853e-02,  9.75272996e-01,  6.91072905e-02,\n",
       "          1.01920265e+00,  5.97540862e-03,  9.97857974e-01,\n",
       "          3.83684204e-02,  1.02476606e+00,  2.47061730e-02,\n",
       "          9.87045767e-01,  3.76783894e-02,  1.00333704e+00,\n",
       "          3.32223977e-02,  9.87857647e-01, -6.11111236e-04,\n",
       "          1.03201657e+00,  5.77717037e-02,  1.03640481e+00,\n",
       "         -1.56084575e-02,  1.01132872e+00,  5.12076334e-03,\n",
       "          1.04217005e+00,  3.24377121e-02,  1.02045243e+00,\n",
       "          2.87243471e-02,  1.02891415e+00, -8.61594378e-03,\n",
       "          1.03485083e+00,  4.93187455e-03,  9.79679592e-01,\n",
       "          5.55392164e-03,  1.04285386e+00, -1.68020801e-02,\n",
       "          9.90207122e-01,  4.35693162e-02,  9.99757704e-01,\n",
       "         -1.61403918e-02,  9.71676783e-01,  5.05928972e-02,\n",
       "          1.02834948e+00,  3.14115582e-02,  9.85608802e-01,\n",
       "         -3.14321935e-02,  1.01668977e+00,  4.04635869e-02,\n",
       "          9.74988018e-01, -2.66243691e-02,  9.86806207e-01,\n",
       "         -1.42476662e-02,  9.89739151e-01, -1.59642461e-03,\n",
       "          9.76719130e-01,  4.84712514e-02,  9.58909619e-01,\n",
       "          2.59675915e-02,  1.02393818e+00, -4.58830929e-04,\n",
       "          1.03968270e+00,  4.90131365e-02,  9.75762257e-01,\n",
       "         -2.17226318e-02,  9.70155193e-01, -3.02576137e-02,\n",
       "          9.86504444e-01, -2.04089918e-02,  9.63050767e-01,\n",
       "          7.44158640e-03,  1.01321554e+00,  3.20662723e-02,\n",
       "          9.88340209e-01, -1.62898085e-02,  1.00541909e+00,\n",
       "          4.91684972e-03,  1.03581317e+00,  3.71195780e-03,\n",
       "          1.03191075e+00, -3.37699397e-02,  1.03718058e+00,\n",
       "         -5.64334761e-03,  1.03856215e+00, -3.12772650e-02,\n",
       "          1.00784455e+00,  6.88131885e-03,  1.00012130e+00,\n",
       "         -2.04665142e-02,  9.59154091e-01, -3.02229207e-02,\n",
       "          9.64882437e-01,  1.02114576e-02,  1.00211915e+00,\n",
       "         -6.16674198e-03,  1.03155174e+00, -9.45534762e-03,\n",
       "          9.94115873e-01, -3.79451849e-02,  9.56035964e-01,\n",
       "          4.09708457e-02,  9.74508957e-01, -2.68548897e-02,\n",
       "          1.02291175e+00,  3.05768987e-02,  9.69756394e-01,\n",
       "          5.37620196e-03,  9.73431910e-01,  8.25117377e-03,\n",
       "          9.81081343e-01, -1.42284518e-02,  1.00959238e+00,\n",
       "          3.91169737e-02,  1.02976567e+00, -4.19545488e-02,\n",
       "          9.75151040e-01,  3.56219058e-02,  1.00881544e+00,\n",
       "         -1.81837211e-02,  1.00261747e+00,  4.26642985e-02,\n",
       "          9.95178858e-01, -4.11557868e-02,  1.00708074e+00,\n",
       "          2.81752999e-02,  1.02777627e+00,  1.86507055e-02,\n",
       "          9.74920391e-01, -1.22521749e-03,  9.99804005e-01,\n",
       "          2.06210362e-02,  9.64468122e-01, -3.50528880e-02,\n",
       "          1.00123485e+00, -3.76673576e-02,  1.02563382e+00,\n",
       "         -1.48621228e-03,  1.04409309e+00, -2.30929308e-02,\n",
       "          9.97809171e-01,  3.45648126e-02,  9.82027332e-01,\n",
       "         -2.19560070e-02,  1.00712728e+00,  1.20277204e-02,\n",
       "          9.88714542e-01,  2.87149788e-02,  9.66030115e-01,\n",
       "          1.53079090e-02,  1.00223479e+00,  3.88254623e-02,\n",
       "          1.02635110e+00,  3.03320542e-02,  1.03471067e+00,\n",
       "         -4.19040220e-02,  1.04221938e+00, -3.42781923e-02,\n",
       "          9.88220644e-01, -2.15416148e-02,  9.78175395e-01,\n",
       "         -3.51627922e-02,  9.65533127e-01, -2.01107067e-02,\n",
       "          9.94341218e-01, -2.25059145e-02,  1.02715301e+00,\n",
       "         -4.20899498e-02,  9.76691339e-01,  4.18012320e-02,\n",
       "          1.03103893e+00,  3.41581528e-02,  1.01867077e+00,\n",
       "          2.34515047e-03,  9.73549681e-01,  2.66340300e-02,\n",
       "          1.01169075e+00,  3.41337903e-02,  1.02824771e+00,\n",
       "          3.52441161e-02,  1.03826894e+00, -4.35799261e-02,\n",
       "          9.70071278e-01,  5.89096229e-03,  1.02856316e+00,\n",
       "          3.27134524e-02,  1.02429100e+00,  3.39476000e-02,\n",
       "          9.77384357e-01,  2.92770062e-02,  9.81780890e-01,\n",
       "         -3.98860270e-02,  1.04039283e+00,  5.97605273e-03,\n",
       "          9.87754647e-01, -1.08940387e-02,  9.81307116e-01,\n",
       "          2.13465343e-02,  1.01940294e+00, -1.16539421e-02,\n",
       "          9.67627466e-01, -1.57265467e-02,  9.98714663e-01,\n",
       "          2.69560619e-02,  9.87403996e-01, -3.12575607e-04,\n",
       "          1.00386441e+00, -3.13761973e-02,  1.00913292e+00,\n",
       "         -6.26187303e-03,  1.01230764e+00,  2.12828819e-02,\n",
       "          9.93989946e-01, -1.22593928e-02,  1.03437423e+00,\n",
       "          2.21741581e-02,  1.02957991e+00,  2.00592415e-02,\n",
       "          1.03834191e+00,  3.29701773e-02,  9.95322839e-01,\n",
       "          3.87722194e-02,  1.02018004e+00,  2.40363542e-02,\n",
       "          9.93811851e-01, -8.98441174e-03,  9.80415256e-01,\n",
       "         -3.75470332e-02,  1.01336377e+00,  3.93098129e-02,\n",
       "          1.03957281e+00, -8.68162736e-03,  1.02689896e+00,\n",
       "          1.66133355e-02,  9.80945705e-01,  8.93763249e-03,\n",
       "          9.75859560e-01,  3.63905178e-02,  1.02404673e+00,\n",
       "          1.41752046e-02,  1.01812779e+00,  3.83133396e-02,\n",
       "          1.03216384e+00, -3.70111061e-03,  9.68617325e-01,\n",
       "          3.69968033e-02,  1.03204296e+00,  7.75907299e-03,\n",
       "          9.93997998e-01, -2.59945408e-02,  9.79924134e-01,\n",
       "          3.82545591e-02,  9.86090445e-01, -2.80995119e-02,\n",
       "          1.04362535e+00,  3.40423361e-02,  1.04023622e+00,\n",
       "          5.03823951e-03,  9.63175284e-01,  3.72587164e-02,\n",
       "          9.83644935e-01,  2.54761230e-02,  1.01958410e+00,\n",
       "          4.29030196e-02,  9.58979523e-01,  4.08273547e-02,\n",
       "          9.58983604e-01, -3.05037870e-02,  9.59651397e-01,\n",
       "         -2.45276886e-02,  1.03260065e+00,  4.04745978e-02,\n",
       "          9.85260997e-01,  1.65137046e-02,  9.84038288e-01,\n",
       "          3.48062059e-02,  1.02586166e+00,  1.77182118e-04,\n",
       "          9.84030452e-01, -3.20282571e-02,  1.02098876e+00,\n",
       "          6.46457814e-03,  9.88581951e-01,  3.46576445e-02,\n",
       "          9.82100494e-01, -4.05193661e-02,  9.90067014e-01,\n",
       "          5.76081901e-04,  9.70673917e-01, -2.43334332e-02,\n",
       "          9.62452029e-01,  4.09367348e-02,  1.03272707e+00,\n",
       "         -1.32678381e-03,  1.03255364e+00,  3.51659480e-02,\n",
       "          9.96439964e-01,  2.93391663e-02,  1.01672481e+00,\n",
       "          2.24867894e-02,  1.03208768e+00, -2.10961362e-02,\n",
       "          9.90445874e-01,  3.94838484e-03,  1.01881524e+00,\n",
       "          1.46032471e-02,  1.02257967e+00,  2.03310769e-02,\n",
       "          9.62777328e-01, -1.41178477e-02,  9.67947419e-01,\n",
       "          4.27614655e-02,  1.02209129e+00,  7.08978817e-04,\n",
       "          1.01830445e+00, -3.38528259e-02,  9.72227980e-01,\n",
       "          1.36817260e-02,  1.02909218e+00,  1.75503771e-02,\n",
       "          1.02667159e+00, -8.84278304e-03,  9.85160039e-01,\n",
       "          9.09034532e-04,  9.85944183e-01, -2.42237242e-02,\n",
       "          9.65544601e-01,  2.90650380e-02,  9.95202289e-01,\n",
       "         -8.31297510e-03,  9.65504743e-01,  4.12999800e-02,\n",
       "          1.00379507e+00,  7.76370795e-03,  1.01091331e+00,\n",
       "         -3.26771211e-02,  1.00724884e+00,  1.31859879e-02,\n",
       "          9.62115810e-01,  2.17486645e-02,  1.01067170e+00,\n",
       "          3.30697680e-02,  1.02224099e+00, -1.34162180e-02,\n",
       "          9.68365213e-01,  3.13727692e-02,  1.00840327e+00,\n",
       "          2.30560408e-02,  1.02824120e+00,  8.49333561e-03,\n",
       "          9.72926903e-01, -8.19607013e-06,  1.03660358e+00,\n",
       "         -2.70657589e-02,  1.04162740e+00, -3.16653423e-02,\n",
       "          1.01872269e+00,  9.48915313e-03,  1.03287643e+00,\n",
       "         -2.16397264e-02,  9.79891359e-01, -2.69788308e-02,\n",
       "          1.01458668e+00, -1.99395355e-02,  1.03770279e+00,\n",
       "         -1.90517342e-02,  9.59791630e-01, -2.12100024e-02,\n",
       "          1.02834325e+00, -2.80777550e-02,  9.76682087e-01,\n",
       "         -3.23110854e-02,  1.02651516e+00,  1.49093002e-02,\n",
       "          1.01248110e+00, -1.38663013e-02,  1.02668368e+00,\n",
       "         -2.71894348e-02,  9.91159804e-01, -2.63856990e-02,\n",
       "          9.95515773e-01, -8.83604923e-03,  1.03756131e+00,\n",
       "          2.68055046e-04,  9.62091017e-01, -2.40896033e-02,\n",
       "          9.69666953e-01,  1.16954687e-02,  1.04166059e+00,\n",
       "         -2.57917578e-02,  1.03652074e+00]])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.85937018e-01, -6.34515843e-01, -5.50710896e-01,\n",
       "        -8.51902686e-01, -2.86224936e-01, -9.31353143e-01,\n",
       "        -9.89046769e-02, -9.93260467e-01,  1.82017336e-01,\n",
       "        -9.55617939e-01,  3.71324908e-01, -9.18628342e-01,\n",
       "         5.28193471e-01, -8.63826493e-01,  6.34522581e-01,\n",
       "        -7.50339574e-01,  7.71559730e-01, -6.30184719e-01,\n",
       "         8.38921728e-01, -4.66002426e-01,  9.00627893e-01,\n",
       "        -4.00272960e-01,  9.58754927e-01, -2.46201249e-01,\n",
       "         9.59297931e-01, -1.12587505e-01,  9.76563491e-01,\n",
       "        -4.48434443e-03,  9.61473686e-01,  1.18479763e-01,\n",
       "         9.92211693e-01,  2.09880965e-01,  9.29493327e-01,\n",
       "         2.93449248e-01,  9.54750155e-01,  4.00182150e-01,\n",
       "         8.49854437e-01,  4.42655550e-01,  8.62171271e-01,\n",
       "         5.33340360e-01,  7.70704544e-01,  6.03180684e-01,\n",
       "         7.34139350e-01,  6.02442166e-01,  7.47649575e-01,\n",
       "         6.65886379e-01,  7.07859050e-01,  7.61143595e-01,\n",
       "         6.37168705e-01,  7.98678042e-01,  6.22182027e-01,\n",
       "         8.32333924e-01,  6.02958699e-01,  7.75974990e-01,\n",
       "         5.27523807e-01,  8.69022816e-01,  5.33206724e-01,\n",
       "         8.99428284e-01,  5.06818557e-01,  9.14908493e-01,\n",
       "         4.02348667e-01,  9.14381505e-01,  3.94539548e-01,\n",
       "         9.24676188e-01,  4.16268535e-01,  9.40473884e-01,\n",
       "         3.96792003e-01,  9.38095474e-01,  3.33957612e-01,\n",
       "         9.65935347e-01,  2.91875378e-01,  9.48617236e-01,\n",
       "         3.37198306e-01,  9.31008433e-01,  2.92259043e-01,\n",
       "         9.25549828e-01,  3.00053841e-01,  1.00250548e+00,\n",
       "         2.45100600e-01,  9.93650671e-01,  2.29353017e-01,\n",
       "         9.46190540e-01,  2.01565928e-01,  1.00664802e+00,\n",
       "         1.73174538e-01,  9.63409607e-01,  2.02070848e-01,\n",
       "         9.95558228e-01,  1.59609363e-01,  9.73090574e-01,\n",
       "         1.82804853e-01,  9.62310441e-01,  1.31211704e-01,\n",
       "         9.60611324e-01,  1.16882871e-01,  9.52874007e-01,\n",
       "         1.06361661e-01,  9.54239822e-01,  1.23724187e-01,\n",
       "         9.54987443e-01,  6.53015837e-02,  9.57953285e-01,\n",
       "         7.17793184e-02,  1.02436752e+00,  1.11412882e-01,\n",
       "         9.97207702e-01,  7.50413583e-02,  9.63375433e-01,\n",
       "         8.45394105e-02,  9.98726587e-01,  7.72955145e-02,\n",
       "         1.00064955e+00,  7.46009702e-02,  9.97313608e-01,\n",
       "         3.06787804e-02,  9.71796444e-01,  2.45904334e-02,\n",
       "         9.92417321e-01,  6.53737116e-02,  1.03116566e+00,\n",
       "         4.45373359e-02,  9.88252069e-01,  9.15562124e-02,\n",
       "         9.99140061e-01,  3.55210355e-02,  1.03684308e+00,\n",
       "         5.48500853e-02,  9.75272996e-01,  6.91072905e-02,\n",
       "         1.01920265e+00,  5.97540862e-03,  9.97857974e-01,\n",
       "         3.83684204e-02,  1.02476606e+00,  2.47061730e-02,\n",
       "         9.87045767e-01,  3.76783894e-02,  1.00333704e+00,\n",
       "         3.32223977e-02,  9.87857647e-01, -6.11111236e-04,\n",
       "         1.03201657e+00,  5.77717037e-02,  1.03640481e+00,\n",
       "        -1.56084575e-02,  1.01132872e+00,  5.12076334e-03,\n",
       "         1.04217005e+00,  3.24377121e-02,  1.02045243e+00,\n",
       "         2.87243471e-02,  1.02891415e+00, -8.61594378e-03,\n",
       "         1.03485083e+00,  4.93187455e-03,  9.79679592e-01,\n",
       "         5.55392164e-03,  1.04285386e+00, -1.68020801e-02,\n",
       "         9.90207122e-01,  4.35693162e-02,  9.99757704e-01,\n",
       "        -1.61403918e-02,  9.71676783e-01,  5.05928972e-02,\n",
       "         1.02834948e+00,  3.14115582e-02,  9.85608802e-01,\n",
       "        -3.14321935e-02,  1.01668977e+00,  4.04635869e-02,\n",
       "         9.74988018e-01, -2.66243691e-02,  9.86806207e-01,\n",
       "        -1.42476662e-02,  9.89739151e-01, -1.59642461e-03,\n",
       "         9.76719130e-01,  4.84712514e-02,  9.58909619e-01,\n",
       "         2.59675915e-02,  1.02393818e+00, -4.58830929e-04,\n",
       "         1.03968270e+00,  4.90131365e-02,  9.75762257e-01,\n",
       "        -2.17226318e-02,  9.70155193e-01, -3.02576137e-02,\n",
       "         9.86504444e-01, -2.04089918e-02,  9.63050767e-01,\n",
       "         7.44158640e-03,  1.01321554e+00,  3.20662723e-02,\n",
       "         9.88340209e-01, -1.62898085e-02,  1.00541909e+00,\n",
       "         4.91684972e-03,  1.03581317e+00,  3.71195780e-03,\n",
       "         1.03191075e+00, -3.37699397e-02,  1.03718058e+00,\n",
       "        -5.64334761e-03,  1.03856215e+00, -3.12772650e-02,\n",
       "         1.00784455e+00,  6.88131885e-03,  1.00012130e+00,\n",
       "        -2.04665142e-02,  9.59154091e-01, -3.02229207e-02,\n",
       "         9.64882437e-01,  1.02114576e-02,  1.00211915e+00,\n",
       "        -6.16674198e-03,  1.03155174e+00, -9.45534762e-03,\n",
       "         9.94115873e-01, -3.79451849e-02,  9.56035964e-01,\n",
       "         4.09708457e-02,  9.74508957e-01, -2.68548897e-02,\n",
       "         1.02291175e+00,  3.05768987e-02,  9.69756394e-01,\n",
       "         5.37620196e-03,  9.73431910e-01,  8.25117377e-03,\n",
       "         9.81081343e-01, -1.42284518e-02,  1.00959238e+00,\n",
       "         3.91169737e-02,  1.02976567e+00, -4.19545488e-02,\n",
       "         9.75151040e-01,  3.56219058e-02,  1.00881544e+00,\n",
       "        -1.81837211e-02,  1.00261747e+00,  4.26642985e-02,\n",
       "         9.95178858e-01, -4.11557868e-02,  1.00708074e+00,\n",
       "         2.81752999e-02,  1.02777627e+00,  1.86507055e-02,\n",
       "         9.74920391e-01, -1.22521749e-03,  9.99804005e-01,\n",
       "         2.06210362e-02,  9.64468122e-01, -3.50528880e-02,\n",
       "         1.00123485e+00, -3.76673576e-02,  1.02563382e+00,\n",
       "        -1.48621228e-03,  1.04409309e+00, -2.30929308e-02,\n",
       "         9.97809171e-01,  3.45648126e-02,  9.82027332e-01,\n",
       "        -2.19560070e-02,  1.00712728e+00,  1.20277204e-02,\n",
       "         9.88714542e-01,  2.87149788e-02,  9.66030115e-01,\n",
       "         1.53079090e-02,  1.00223479e+00,  3.88254623e-02,\n",
       "         1.02635110e+00,  3.03320542e-02,  1.03471067e+00,\n",
       "        -4.19040220e-02,  1.04221938e+00, -3.42781923e-02,\n",
       "         9.88220644e-01, -2.15416148e-02,  9.78175395e-01,\n",
       "        -3.51627922e-02,  9.65533127e-01, -2.01107067e-02,\n",
       "         9.94341218e-01, -2.25059145e-02,  1.02715301e+00,\n",
       "        -4.20899498e-02,  9.76691339e-01,  4.18012320e-02,\n",
       "         1.03103893e+00,  3.41581528e-02,  1.01867077e+00,\n",
       "         2.34515047e-03,  9.73549681e-01,  2.66340300e-02,\n",
       "         1.01169075e+00,  3.41337903e-02,  1.02824771e+00,\n",
       "         3.52441161e-02,  1.03826894e+00, -4.35799261e-02,\n",
       "         9.70071278e-01,  5.89096229e-03,  1.02856316e+00,\n",
       "         3.27134524e-02,  1.02429100e+00,  3.39476000e-02,\n",
       "         9.77384357e-01,  2.92770062e-02,  9.81780890e-01,\n",
       "        -3.98860270e-02,  1.04039283e+00,  5.97605273e-03,\n",
       "         9.87754647e-01, -1.08940387e-02,  9.81307116e-01,\n",
       "         2.13465343e-02,  1.01940294e+00, -1.16539421e-02,\n",
       "         9.67627466e-01, -1.57265467e-02,  9.98714663e-01,\n",
       "         2.69560619e-02,  9.87403996e-01, -3.12575607e-04,\n",
       "         1.00386441e+00, -3.13761973e-02,  1.00913292e+00,\n",
       "        -6.26187303e-03,  1.01230764e+00,  2.12828819e-02,\n",
       "         9.93989946e-01, -1.22593928e-02,  1.03437423e+00,\n",
       "         2.21741581e-02,  1.02957991e+00,  2.00592415e-02,\n",
       "         1.03834191e+00,  3.29701773e-02,  9.95322839e-01,\n",
       "         3.87722194e-02,  1.02018004e+00,  2.40363542e-02,\n",
       "         9.93811851e-01, -8.98441174e-03,  9.80415256e-01,\n",
       "        -3.75470332e-02,  1.01336377e+00,  3.93098129e-02,\n",
       "         1.03957281e+00, -8.68162736e-03,  1.02689896e+00,\n",
       "         1.66133355e-02,  9.80945705e-01,  8.93763249e-03,\n",
       "         9.75859560e-01,  3.63905178e-02,  1.02404673e+00,\n",
       "         1.41752046e-02,  1.01812779e+00,  3.83133396e-02,\n",
       "         1.03216384e+00, -3.70111061e-03,  9.68617325e-01,\n",
       "         3.69968033e-02,  1.03204296e+00,  7.75907299e-03,\n",
       "         9.93997998e-01, -2.59945408e-02,  9.79924134e-01,\n",
       "         3.82545591e-02,  9.86090445e-01, -2.80995119e-02,\n",
       "         1.04362535e+00,  3.40423361e-02,  1.04023622e+00,\n",
       "         5.03823951e-03,  9.63175284e-01,  3.72587164e-02,\n",
       "         9.83644935e-01,  2.54761230e-02,  1.01958410e+00,\n",
       "         4.29030196e-02,  9.58979523e-01,  4.08273547e-02,\n",
       "         9.58983604e-01, -3.05037870e-02,  9.59651397e-01,\n",
       "        -2.45276886e-02,  1.03260065e+00,  4.04745978e-02,\n",
       "         9.85260997e-01,  1.65137046e-02,  9.84038288e-01,\n",
       "         3.48062059e-02,  1.02586166e+00,  1.77182118e-04,\n",
       "         9.84030452e-01, -3.20282571e-02,  1.02098876e+00,\n",
       "         6.46457814e-03,  9.88581951e-01,  3.46576445e-02,\n",
       "         9.82100494e-01, -4.05193661e-02,  9.90067014e-01,\n",
       "         5.76081901e-04,  9.70673917e-01, -2.43334332e-02,\n",
       "         9.62452029e-01,  4.09367348e-02,  1.03272707e+00,\n",
       "        -1.32678381e-03,  1.03255364e+00,  3.51659480e-02,\n",
       "         9.96439964e-01,  2.93391663e-02,  1.01672481e+00,\n",
       "         2.24867894e-02,  1.03208768e+00, -2.10961362e-02,\n",
       "         9.90445874e-01,  3.94838484e-03,  1.01881524e+00,\n",
       "         1.46032471e-02,  1.02257967e+00,  2.03310769e-02,\n",
       "         9.62777328e-01, -1.41178477e-02,  9.67947419e-01,\n",
       "         4.27614655e-02,  1.02209129e+00,  7.08978817e-04,\n",
       "         1.01830445e+00, -3.38528259e-02,  9.72227980e-01,\n",
       "         1.36817260e-02,  1.02909218e+00,  1.75503771e-02,\n",
       "         1.02667159e+00, -8.84278304e-03,  9.85160039e-01,\n",
       "         9.09034532e-04,  9.85944183e-01, -2.42237242e-02,\n",
       "         9.65544601e-01,  2.90650380e-02,  9.95202289e-01,\n",
       "        -8.31297510e-03,  9.65504743e-01,  4.12999800e-02,\n",
       "         1.00379507e+00,  7.76370795e-03,  1.01091331e+00,\n",
       "        -3.26771211e-02,  1.00724884e+00,  1.31859879e-02,\n",
       "         9.62115810e-01,  2.17486645e-02,  1.01067170e+00,\n",
       "         3.30697680e-02,  1.02224099e+00, -1.34162180e-02,\n",
       "         9.68365213e-01,  3.13727692e-02,  1.00840327e+00,\n",
       "         2.30560408e-02,  1.02824120e+00,  8.49333561e-03,\n",
       "         9.72926903e-01, -8.19607013e-06,  1.03660358e+00,\n",
       "        -2.70657589e-02,  1.04162740e+00, -3.16653423e-02,\n",
       "         1.01872269e+00,  9.48915313e-03,  1.03287643e+00,\n",
       "        -2.16397264e-02,  9.79891359e-01, -2.69788308e-02,\n",
       "         1.01458668e+00, -1.99395355e-02,  1.03770279e+00,\n",
       "        -1.90517342e-02,  9.59791630e-01, -2.12100024e-02,\n",
       "         1.02834325e+00, -2.80777550e-02,  9.76682087e-01,\n",
       "        -3.23110854e-02,  1.02651516e+00,  1.49093002e-02,\n",
       "         1.01248110e+00, -1.38663013e-02,  1.02668368e+00,\n",
       "        -2.71894348e-02,  9.91159804e-01, -2.63856990e-02,\n",
       "         9.95515773e-01, -8.83604923e-03,  1.03756131e+00,\n",
       "         2.68055046e-04,  9.62091017e-01, -2.40896033e-02,\n",
       "         9.69666953e-01,  1.16954687e-02,  1.04166059e+00,\n",
       "        -2.57917578e-02,  1.03652074e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
