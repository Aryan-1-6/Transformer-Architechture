{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from nltk.tokenize import word_tokenize\n",
    "from src.MPNeuronInfo import Loss_CrossCategoricalEntropy, OptimizerAdam\n",
    "from src.transformer import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = [\"\"\"\n",
    "The cat is sleeping on the bed while the dog is barking loudly near the street full of cars. \n",
    "The sun is shining brightly above the sky, and the bird is flying high near the mountains. \n",
    "The child is running in the park, and the flower is blooming beautifully in the garden. \n",
    "The man is eating an apple while the woman is reading a book. \n",
    "The boy is playing football and the girl is singing a song happily. \n",
    "The apple is red and sweet, the sky is blue today, and the water is cold and fresh. \n",
    "The food is tasty and hot, and the street is busy with cars and people waiting in line. \n",
    "The teacher is writing on the board, and the students are studying hard. \n",
    "The baby is crying loudly while the family is having dinner together and the friends are talking happily. \n",
    "The dog is sleeping under the tree while the cat is drinking milk. \n",
    "The birds are building a nest and the sun sets behind the mountains. \n",
    "The stars are shining at night, the wind is blowing softly, and the rain is falling on the roof. \n",
    "The car is moving fast, the train is arriving at the station, and the airplane is flying high in the sky. \n",
    "The boy is eating ice cream, the girl is watching television, the man is driving a car, and the woman is cooking food. \n",
    "The children are playing together while the phone is ringing loudly, the clock is ticking slowly, the lights are glowing brightly, and the music is playing softly.\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "corpus_sp = [\"\"\"El gato está durmiendo en la cama mientras el perro está ladrando fuerte cerca de la calle llena de coches. \n",
    "El sol está brillando intensamente sobre el cielo, y el pájaro está volando alto cerca de las montañas. \n",
    "El niño está corriendo en el parque, y la flor está floreciendo hermosamente en el jardín. \n",
    "El hombre está comiendo una manzana mientras la mujer está leyendo un libro. \n",
    "El chico está jugando al fútbol y la niña está cantando una canción felizmente. \n",
    "La manzana es roja y dulce, el cielo está azul hoy, y el agua está fría y fresca. \n",
    "La comida está sabrosa y caliente, y la calle está ocupada con coches y personas esperando en la fila. \n",
    "El maestro está escribiendo en la pizarra mientras los estudiantes están estudiando mucho. \n",
    "El bebé está llorando fuerte mientras la familia está cenando junta y los amigos están hablando felices. \n",
    "El perro está durmiendo bajo el árbol mientras el gato está bebiendo leche. \n",
    "Los pájaros están construyendo un nido y el sol se pone detrás de las montañas. \n",
    "Las estrellas están brillando por la noche, el viento está soplando suavemente, y la lluvia está cayendo sobre el techo. \n",
    "El coche se mueve rápido, el tren está llegando a la estación, y el avión está volando alto en el cielo. \n",
    "El chico está comiendo helado, la niña está viendo televisión, el hombre está conduciendo un coche, y la mujer está cocinando comida. \n",
    "Los niños están jugando juntos mientras el teléfono está sonando fuerte, el reloj está marcando lentamente, las luces están brillando intensamente, y la música está sonando suavemente.\"\"\"]\n",
    "\n",
    "\n",
    "\n",
    "corpus[0] += ' eos'\n",
    "corpus_sp[0] += ' eos'\n",
    "\n",
    "e = Encoder(corpus, 4)\n",
    "d = Decoder(corpus_sp, 4)\n",
    "\n",
    "e_embd = []\n",
    "\n",
    "input = [\n",
    "    \"the cat is sleeping\",\n",
    "    \"the dog is barking\",\n",
    "    \"the sun is shining\",\n",
    "    \"the bird is flying\",\n",
    "    \"the child is running\",\n",
    "]\n",
    "    # \"the flower is blooming\",\n",
    "    # \"the man is eating\",\n",
    "    # \"the woman is reading\",\n",
    "    # \"the boy is playing\",\n",
    "    # \"the girl is singing\",\n",
    "    # \"the apple is red\",\n",
    "    # \"the sky is blue\",\n",
    "    # \"the water is cold\",\n",
    "    # \"the food is tasty\",\n",
    "    # \"the street is busy\"\n",
    "tokenized_input = [word_tokenize(sentence.lower()) for sentence in input]\n",
    "n = len(tokenized_input[0])\n",
    "\n",
    "decoder_input = [\n",
    "    \"el gato está durmiendo\",\n",
    "    \"el perro está ladrando\",\n",
    "    \"el sol está brillando\",\n",
    "    \"el pájaro está volando\",\n",
    "    \"el niño está corriendo\",\n",
    "\n",
    "]\n",
    "\n",
    "    # \"la flor está floreciendo\",\n",
    "    # \"el hombre está comiendo\",\n",
    "    # \"la mujer está leyendo\",\n",
    "    # \"el chico está jugando\",\n",
    "    # \"la niña está cantando\",\n",
    "    # \"la manzana es roja\",\n",
    "    # \"el cielo es azul\",\n",
    "    # \"el agua está fría\",\n",
    "    # \"la comida es sabrosa\",\n",
    "    # \"la calle está ocupada\"\n",
    "\n",
    "d_tokenized_input = [word_tokenize(sentence.lower()) for sentence in decoder_input]\n",
    "m = len(d_tokenized_input[0])\n",
    "\n",
    "e.vocab_creation()\n",
    "print(\"Vocab created for English\")\n",
    "e.word_embeddings()\n",
    "e.positional_encoding(n+2)\n",
    "e.query_key_value()\n",
    "e.feed_forward()\n",
    "e.ed_key_value()\n",
    "\n",
    "d.vocab_creation()\n",
    "print(\"Vocab created for Spanish \\n\")\n",
    "d.word_embeddings()\n",
    "d.positional_encoding(m+1)\n",
    "d.query_key_value()\n",
    "d.feed_forward()\n",
    "d.ed_query()\n",
    "d.next_word()\n",
    "\n",
    "e.map(tokenized_input)\n",
    "d.map(d_tokenized_input)\n",
    "d.casual_mask(m+1)\n",
    "d.label(d_tokenized_input)\n",
    "\n",
    "loss_fn = Loss_CrossCategoricalEntropy()\n",
    "y_train = d.one_hot(np.array(d.label), len(d.vocab)-1)\n",
    "\n",
    "print(\"Mapped Encoder input : \\n\", e.input,\"\\n\")\n",
    "print(\"Mapped Decoder input : \\n\", d.input,\"\\n\")\n",
    "\n",
    "print(\"Mask created for Decoder - Masked Self Attention : \\n\",d.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(d_tokenized_input[0])\n",
    "warmup_steps = 4000\n",
    "f=0\n",
    "lrate = 0.00001\n",
    "for i in range(0, 500):\n",
    "    result = []\n",
    "    count = 0\n",
    "    while count != max_len :\n",
    "        count += 1\n",
    "        steps = count + max_len * i\n",
    "        # lrate = d.embd_dim ** -0.5 * min(steps ** -0.5, steps * warmup_steps ** -1.5)\n",
    "        \n",
    "        # lrate = custom_lr(steps, total_steps=2000, warmup_steps=100, base_lr=2e-3, min_lr=1e-5)\n",
    "        # lrate = initial_lr * (decay_rate ** (steps / decay_steps))\n",
    "\n",
    "        optimizer = OptimizerAdam(learning_rate=lrate)\n",
    "\n",
    "        ewe = e.embeddings[(np.array(e.input)).tolist()]\n",
    "        ewe += e.position_encodings\n",
    "\n",
    "        e.self_attention(ewe, n)\n",
    "        e.res = e.layer_normalization(e.res)\n",
    "\n",
    "        e.ffn1.forward(e.res)\n",
    "        e.ffnact.forward(e.ffn1.output)\n",
    "        e.ffn2.forward(e.ffnact.output)\n",
    "\n",
    "        e.res += e.ffn2.output\n",
    "        e.res = e.layer_normalization(e.res)\n",
    "        \n",
    "        dwe = d.embeddings[(np.array(d.input)).tolist()]\n",
    "        dwe += d.position_encodings\n",
    "\n",
    "        d.self_attention(dwe, m)\n",
    "        d.res = d.layer_normalization(d.res)\n",
    "\n",
    "        d.ed_attention(e)\n",
    "        d.final = d.layer_normalization(d.final)\n",
    "\n",
    "        d.nxtlayer.forward(d.final)\n",
    "        d.nxtactivation.forward(d.nxtlayer.output)\n",
    "        d.nxtlayer2.forward(d.nxtactivation.output)\n",
    "        d.nxtlayer2.output += d.final\n",
    "        d.nxtlayer2.output = d.layer_normalization(d.nxtlayer2.output)\n",
    "        \n",
    "        d.vocablayer.forward(d.nxtlayer2.output)\n",
    "        d.activation3.forward(d.vocablayer.output)\n",
    "\n",
    "        check = np.argmax(d.activation3.output, axis=2)\n",
    "\n",
    "        # Predicted IDs\n",
    "        # print(check)\n",
    "\n",
    "        # Calculate loss \n",
    "        loss_fn.backward(d.activation3.output, np.array(y_train))\n",
    "\n",
    "        d.activation3.backward((loss_fn.dinputs))\n",
    "        d.vocablayer.backward(d.activation3.dinputs)\n",
    "        d.nxtlayer2.backward(d.vocablayer.dinputs)\n",
    "        d.nxtactivation.backward(d.nxtlayer2.dinputs)\n",
    "        d.nxtlayer.backward(d.nxtactivation.dinputs)\n",
    "       \n",
    "       \n",
    "        diff = loss_fn.calculate(d.activation3.output, np.array(y_train))\n",
    "        print(\"Loss : \",diff)\n",
    "\n",
    "        # encoder decoder attention layer \n",
    "        ed_v_new_dvals = np.matmul(d.activation2.output.transpose(0,2,1), d.nxtlayer.dinputs)\n",
    "        e.ed_vlayer.backward(ed_v_new_dvals)\n",
    "\n",
    "        ed_softmax_dvals = np.matmul(d.nxtlayer.dinputs, e.ed_vlayer.output.transpose(0,2,1))\n",
    "        d.activation2.backward(ed_softmax_dvals)\n",
    "\n",
    "        ed_q_new_dvals = np.matmul(d.activation2.dinputs, e.ed_klayer.output)\n",
    "        d.ed_qlayer.backward(ed_q_new_dvals)\n",
    "        \n",
    "        ed_k_new_dvals = np.matmul(d.activation2.dinputs.transpose(0,2,1), d.ed_qlayer.output)\n",
    "        e.ed_klayer.backward(ed_k_new_dvals)\n",
    "\n",
    "        # decoder attention layer\n",
    "        d_v_new_dvals = np.matmul(d.activation.output.transpose(0,2,1), d.ed_qlayer.dinputs)\n",
    "        d.vlayer.backward(d_v_new_dvals)\n",
    "\n",
    "        d_softmax_dvals = np.matmul(d.ed_qlayer.dinputs, d.vlayer.output.transpose(0,2,1))\n",
    "        d.activation.backward(d_softmax_dvals)\n",
    "\n",
    "        d_q_new_dvals = np.matmul(d.activation.dinputs, d.klayer.output)\n",
    "        d.qlayer.backward(d_q_new_dvals)\n",
    "\n",
    "        d_k_new_dvals = np.matmul(d.activation.dinputs, d.qlayer.output)\n",
    "        d.klayer.backward(d_k_new_dvals)\n",
    "\n",
    "        # encoder attention layer\n",
    "        encoder_dinputs = e.ed_vlayer.dinputs + e.ed_klayer.dinputs\n",
    "\n",
    "        e.ffn2.backward(encoder_dinputs)\n",
    "        e.ffnact.backward(e.ffn2.dinputs)\n",
    "        e.ffn1.backward(e.ffnact.dinputs)\n",
    "\n",
    "        e_v_new_dvals = np.matmul(e.activation.output.transpose(0,2,1), encoder_dinputs)\n",
    "        e.vlayer.backward(e_v_new_dvals)\n",
    "\n",
    "        e_softmax_dvals = np.matmul(encoder_dinputs, e.vlayer.output.transpose(0,2,1))\n",
    "        e.activation.backward(e_softmax_dvals)\n",
    "\n",
    "        e_q_new_dvals = np.matmul(e.activation.dinputs, e.klayer.output)\n",
    "        e.qlayer.backward(e_q_new_dvals)\n",
    "        \n",
    "        e_k_new_dvals = np.matmul(e.activation.dinputs, e.qlayer.output)\n",
    "        e.klayer.backward(e_k_new_dvals) \n",
    "        \n",
    "        optimizer.update_params(d.vocablayer)\n",
    "        optimizer.update_params(d.nxtlayer2)\n",
    "        optimizer.update_params(d.nxtlayer)\n",
    "\n",
    "        optimizer.update_params(e.ed_vlayer)\n",
    "        optimizer.update_params(e.ed_klayer)\n",
    "        optimizer.update_params(d.ed_qlayer)\n",
    "\n",
    "        optimizer.update_params(d.vlayer)\n",
    "        optimizer.update_params(d.klayer)\n",
    "        optimizer.update_params(d.qlayer)\n",
    "        \n",
    "        optimizer.update_params(e.ffn2)\n",
    "        optimizer.update_params(e.ffn1)\n",
    "\n",
    "        optimizer.update_params(e.vlayer)\n",
    "        optimizer.update_params(e.klayer)\n",
    "        optimizer.update_params(e.qlayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [\"the cat is sleeping\"]\n",
    "d_input = []\n",
    "tokenized_input = [word_tokenize(sentence.lower()) for sentence in input]\n",
    "d_tki = [[0]]\n",
    "\n",
    "n = len(tokenized_input[0])\n",
    "e.positional_encoding(n)\n",
    "e.map(tokenized_input)\n",
    "e.input = [e.input[0][1:-1]]\n",
    "print(e.input)\n",
    "ewe = e.embeddings[(np.array(e.input)).tolist()]\n",
    "e.self_attention(ewe, n)\n",
    "e.res = e.layer_normalization(e.res)\n",
    "e.ffn1.forward(e.res)\n",
    "e.ffnact.forward(e.ffn1.output)\n",
    "e.ffn2.forward(e.ffnact.output)\n",
    "\n",
    "e.res += e.ffn2.output\n",
    "e.res = e.layer_normalization(e.res)\n",
    "flag = 1\n",
    "\n",
    "for _ in range(n):\n",
    "    # d.map(d_tki)\n",
    "    m = len(d_tki)\n",
    "    d.positional_encoding(m)\n",
    "    d.casual_mask(m)\n",
    "\n",
    "    dwe = d.embeddings[(np.array(d_tki)).tolist()]\n",
    "    dwe += d.position_encodings\n",
    "\n",
    "    d.self_attention(dwe, m)\n",
    "    d.res = d.layer_normalization(d.res)\n",
    "\n",
    "    print(\"e.res shape:\", e.res.shape)          \n",
    "    print(\"d.final shape before ed_attention:\", d.res.shape) \n",
    "\n",
    "    d.ed_attention(e)\n",
    "    d.final = d.layer_normalization(d.final)\n",
    "\n",
    "    d.nxtlayer.forward(d.final)\n",
    "    d.nxtactivation.forward(d.nxtlayer.output)\n",
    "    d.nxtlayer2.forward(d.nxtactivation.output)\n",
    "    d.nxtlayer2.output += d.final\n",
    "    d.nxtlayer2.output = d.layer_normalization(d.nxtlayer2.output)\n",
    "    \n",
    "    d.vocablayer.forward(d.nxtlayer2.output)\n",
    "    d.activation3.forward(d.vocablayer.output)\n",
    "\n",
    "    probs_last = d.activation3.output[0, -1]   \n",
    "    \n",
    "    topk = 10\n",
    "    idxs = np.argsort(probs_last)[-topk:][::-1]\n",
    "    print(\"top probs:\", [(int(i), float(probs_last[i])) for i in idxs])\n",
    "    \n",
    "    check = int(np.argmax(probs_last))\n",
    "    print(check)\n",
    "\n",
    "    d_tki[0].append(check)\n",
    "    print(d_tki)\n",
    "\n",
    "    if check == 126:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume gold target tokens from training for \"the cat is sleeping\" were [1,2,3,4,126] (your print)\n",
    "gold = [1,2,3,4,126]\n",
    "d_tki = [[0]]  # sos\n",
    "for t in range(len(gold)):\n",
    "    # feed decoder with ground-truth tokens up to t (teacher forcing)\n",
    "    seq = [0] + gold[:t]   # 0 is sos\n",
    "    d_tki = [seq]\n",
    "    # do decoder forward exactly as in inference\n",
    "    dwe = d.embeddings[np.array(d_tki).tolist()]\n",
    "    dwe += d.position_encodings[:len(seq)]\n",
    "    d.self_attention(dwe, len(seq))\n",
    "    d.ed_attention(e)\n",
    "    d.nxtlayer.forward(d.final)  # etc - run through to logits\n",
    "    d.vocablayer.forward(d.nxtlayer2.output)\n",
    "    d.activation3.forward(d.vocablayer.output)\n",
    "    # check last-step argmax\n",
    "    probs_last = d.activation3.output[0, -1]\n",
    "    print(\"step\", t, \"pred:\", int(np.argmax(probs_last)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.label\n",
    "# En el corazón de la bulliciosa ciudad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
